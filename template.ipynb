{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa00761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda create -n trident python=3.10\n",
    "# cd trident\n",
    "# pip install -e .\n",
    "# pip install ipynbname\n",
    "# pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2117c640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynbname\n",
    "import os\n",
    "\n",
    "this_notebook_name = ipynbname.name()\n",
    "feats_save_dir = \"feats_h5\"\n",
    "\n",
    "if not os.path.exists(feats_save_dir):\n",
    "    os.mkdir(feats_save_dir)\n",
    "\n",
    "import json\n",
    "import h5py\n",
    "import logging\n",
    "\n",
    "from PIL import Image, ImageFile, PngImagePlugin\n",
    "Image.MAX_IMAGE_PIXELS = None \n",
    "PngImagePlugin.MAX_TEXT_CHUNK = 100 * 1024 * 1024  # 100MB\n",
    "PngImagePlugin.MAX_TEXT_MEMORY = 100 * 1024 * 1024 # 100MB\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import torch.multiprocessing\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import timm\n",
    "from trident.patch_encoder_models import encoder_factory\n",
    "\n",
    "from plot import draw_attention_mask\n",
    "from helpers import CustomDataset, custom_extract_patch_features_from_dataloader\n",
    "\n",
    "dataDir = Path(\"/Z/cuhk_data/HPACG_dataHPACG_split\")\n",
    "train_positive_dir = dataDir / \"train/positive\"\n",
    "train_negative_dir = dataDir / \"train/negative\"\n",
    "\n",
    "test_positive_dir = dataDir / \"test/positive\"\n",
    "test_negative_dir = dataDir / \"test/negative\"\n",
    "\n",
    "def get_random_img_path():\n",
    "    rand_img = random.choice(os.listdir(dataDir / \"train/positive\"))\n",
    "    rand_img_full_path = dataDir / \"train/positive\" / rand_img\n",
    "\n",
    "    return rand_img_full_path\n",
    "\n",
    "if not os.path.exists(dataDir):\n",
    "    raise Exception(\"dataDir not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1859cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = encoder_factory(model_name='conch_v15')\n",
    "\n",
    "    def get_eval_transforms_conchv1_5(img_resize: int = 448):\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(\n",
    "                    img_resize, interpolation=transforms.InterpolationMode.BICUBIC\n",
    "                ),\n",
    "                transforms.CenterCrop(img_resize),\n",
    "                transforms.Lambda(\n",
    "                    lambda img: img.convert(\"RGB\") if img.mode != \"RGB\" else img\n",
    "                ),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ]\n",
    "        )\n",
    "        return transform\n",
    "\n",
    "    transform = get_eval_transforms_conchv1_5()\n",
    "\n",
    "    return model, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d699c94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toom/miniconda3/envs/trident/lib/python3.10/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from os.path import join as j_\n",
    "from UNI.uni.downstream.extract_patch_features import extract_patch_features_from_dataloader\n",
    "from UNI.uni.downstream.eval_patch_features.linear_probe import eval_linear_probe\n",
    "\n",
    "model, trnsfrms_val = get_model()\n",
    "\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#   print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#   model = nn.DataParallel(model)\n",
    "model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "train_dataset = CustomDataset(dataDir / 'train', transform=trnsfrms_val)\n",
    "test_dataset = CustomDataset(dataDir / 'test', transform=trnsfrms_val)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=False, num_workers=8)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a6d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = custom_extract_patch_features_from_dataloader(model, train_dataloader)\n",
    "test_features = custom_extract_patch_features_from_dataloader(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80182de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = torch.Tensor(train_features['embeddings'])\n",
    "train_labels = torch.Tensor(train_features['labels']).type(torch.long)\n",
    "test_feats = torch.Tensor(test_features['embeddings'])\n",
    "test_labels = torch.Tensor(test_features['labels']).type(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30086fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from UNI.uni.downstream.eval_patch_features.metrics import get_eval_metrics, print_metrics\n",
    "\n",
    "linprobe_eval_metrics, linprobe_dump = eval_linear_probe(\n",
    "    train_feats = train_feats,\n",
    "    train_labels = train_labels,\n",
    "    valid_feats = None ,\n",
    "    valid_labels = None,\n",
    "    test_feats = test_feats,\n",
    "    test_labels = test_labels,\n",
    "    max_iter = 1000,\n",
    "    verbose= True,\n",
    ")\n",
    "\n",
    "print_metrics(linprobe_eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3929d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "y_true = linprobe_dump['preds_all']\n",
    "y_pred = linprobe_dump['targets_all']\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "labels = ['non-hpacg', 'hpacg']\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap='Blues')\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix=cm.ravel()\n",
    "\n",
    "tpr = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "fpr = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "specificity = TN / (TN + FP) if (FP + TN) > 0 else 0\n",
    "Balanced_Accuracy = (specificity + tpr) / 2\n",
    "Precision = TP  / (TP + FP) if (TP + FP) > 0 else 0\n",
    "Weight_F1 = ((Precision * tpr) / (Precision + tpr))*2\n",
    "\n",
    "print(f\"True Positive Rate (Sensitivity,recall): [{tpr:.3f}]\")\n",
    "print(f\"False Positive Rate : [{fpr:.3f}]\")\n",
    "print(f\"Specificity : [{specificity:.3f}]\")\n",
    "print(f\"Balanced Accuracy : [{Balanced_Accuracy:.3f}]\")\n",
    "print(f\"Precision: [{Precision:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67fc8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "true_labels = linprobe_dump['targets_all']\n",
    "pred_probs = linprobe_dump['probs_all']\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'UNI (AUC={roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')  \n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438bf4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677b64a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trident",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
